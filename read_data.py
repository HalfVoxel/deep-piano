import music21
from music21 import *
import pretty_midi as pm
import glob
import pickle
from pickle import load, dump
from recordclass import recordclass


Chord = recordclass("Chord", "start end notes")
def merge_notes(notes):
    result = []
    for note in notes:
        if len(result) > 0 and result[-1].start == note.start and result[-1].end == note.end:
            if isinstance(result[-1], Chord):
                result[-1].notes.append(note)
            else:
                result[-1] = Chord(note.start, note.end, [result[-1], note])
        else:
            result.append(note)


    return result


def quantize(midi, tracks):
    quanta = int(midi.time_to_tick(60/midi.get_tempo_changes()[1][0])/6)  # min(durations)
    durations = []
    for _,_,track in tracks:
        for note in track:
            note.start = midi.tick_to_time(quanta*int(round(midi.time_to_tick(note.start)/quanta)))
            # note.end = midi.tick_to_time(quanta*int(round(midi.time_to_tick(note.end)/quanta)))
            duration = midi.time_to_tick((note.end - note.start)/quanta)
            note.end = note.start + midi.tick_to_time(duration) * quanta
            print(note.start/quanta)
            if isinstance(note, Chord):
                for n in note.notes:
                    n.start = note.start
                    n.end = note.end
            durations.append(midi.time_to_tick(note.start))

    durations = [x/quanta for x in durations]
    for x in durations:
        if abs(x - round(x)) > 0.1:
            print("Failed to quantize: " + str(x))
            print(durations)
            exit(1)


def get_notes():
    """ Get all the notes and chords from the midi files in the data directory """
    notes = []
    # for file in glob.glob('data/final_fantasy/*.mid'):  # only reads Bach
    for file in glob.glob('data/bach/*/*.mid'):  # only reads Bach
        print("Parsing %s" % file)
        midi = converter.parse(file)

        notes_to_parse = midi.elements[0].flat.notes
        highest_time = -1

        for element in notes_to_parse:
            if element.offset < highest_time:
                continue
            if isinstance(element, note.Note):
                notes.append(str(element.pitch) + ":" + str(float(element.duration.quarterLength)))
            elif isinstance(element, chord.Chord):
                notes.append('.'.join(str(n) for n in element.normalOrder) + ":" + str(float(element.duration.quarterLength)))
            highest_time = element.offset + element.duration.quarterLength

    # midi_stream = stream.Stream(convert_to_notes(notes))
    # midi_stream.write('midi', fp='all.mid')

    with open('data/notes/notes.pickle', 'wb') as f:
        pickle.dump(notes, f)

    return notes


def get_pickle():

    with open('data/notes/notes.pickle', 'rb') as f:
        unpickled = load(f)

    return unpickled


def convert_to_notes(input_notes):
    # create stream from predictions
    offset = 0
    output_notes = []
    # create note and chord objects based on the values generated by the model
    for noteStr in input_notes:
        pattern, duration = noteStr.split(":")
        # pattern is a chord
        if ('.' in pattern) or pattern.isdigit():
            notes_in_chord = pattern.split('.')
            notes = []
            for current_note in notes_in_chord:
                new_note = note.Note(int(current_note))
                new_note.storedInstrument = instrument.Piano()
                notes.append(new_note)
            new_element = chord.Chord(notes)
        # pattern is a note
        else:
            new_element = note.Note(pattern)
            new_element.storedInstrument = instrument.Piano()

        duration = float(duration)
        new_element.duration.quarterLength = duration
        new_element.offset = offset
        output_notes.append(new_element)
        # increase offset each iteration so that notes do not stack
        offset += duration
    return output_notes

if __name__ == "__main__":
    x = get_notes()
    print(x)
